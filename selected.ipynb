{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())\n"
      ],
      "metadata": {
        "id": "HjHc8yVCFBiT",
        "outputId": "0e283efb-a5bd-4cb8-a8cd-6cd6a626c11e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 12503724402839210938\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist,cifar10\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(X_train_fashion, y_train_fashion), (X_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(X_train_cifar, y_train_cifar), (X_test_cifar, y_test_cifar) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "dbDeANks9u1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "X_train_mnist, X_test_mnist = X_train_mnist / 255.0, X_test_mnist / 255.0\n",
        "X_train_fashion, X_test_fashion = X_train_fashion / 255.0, X_test_fashion / 255.0\n",
        "X_train_cifar, X_test_cifar = X_train_cifar / 255.0, X_test_cifar / 255.0\n",
        "\n",
        "y_train_mnist = tf.keras.utils.to_categorical(y_train_mnist, num_classes=10)\n",
        "y_test_mnist = tf.keras.utils.to_categorical(y_test_mnist, num_classes=10)\n",
        "y_train_fashion = tf.keras.utils.to_categorical(y_train_fashion, num_classes=10)\n",
        "y_test_fashion = tf.keras.utils.to_categorical(y_test_fashion, num_classes=10)\n",
        "y_train_cifar = tf.keras.utils.to_categorical(y_train_cifar, num_classes=10)\n",
        "y_test_cifar = tf.keras.utils.to_categorical(y_test_cifar, num_classes=10)\n"
      ],
      "metadata": {
        "id": "8F2kU7At9zoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST\n",
        "model_mnist = models.Sequential([\n",
        "    layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(120, activation='relu'),\n",
        "    layers.Dense(84, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_mnist.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mnist.fit(X_train_mnist, y_train_mnist, epochs=10, batch_size=64, validation_data=(X_test_mnist, y_test_mnist))\n",
        "\n",
        "model_mnist.summary()\n",
        "for layer in model_mnist.layers:\n",
        "    print(layer.name, layer.count_params())\n",
        "\n",
        "y_pred_mnist = model_mnist.predict(X_test_mnist)\n",
        "y_pred_classes_mnist = np.argmax(y_pred_mnist, axis=1)\n",
        "y_true_mnist = np.argmax(y_test_mnist, axis=1)\n",
        "\n",
        "confusion_mnist = confusion_matrix(y_true_mnist, y_pred_classes_mnist)\n",
        "precision_mnist = precision_score(y_true_mnist, y_pred_classes_mnist, average='weighted')\n",
        "recall_mnist = recall_score(y_true_mnist, y_pred_classes_mnist, average='weighted')\n",
        "f1_mnist = f1_score(y_true_mnist, y_pred_classes_mnist, average='weighted')\n",
        "\n",
        "print(\"(MNIST):\")\n",
        "print(\"Confusion Matrix :\")\n",
        "print(confusion_mnist)\n",
        "print(f\"Precision: {precision_mnist}\")\n",
        "print(f\"Recall: {recall_mnist}\")\n",
        "print(f\"F1 Score: {f1_mnist}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZb8WS6S98k8",
        "outputId": "172c7415-1c6c-432c-dcc2-f5e7c1e7aef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 37s 37ms/step - loss: 0.2318 - accuracy: 0.9319 - val_loss: 0.0706 - val_accuracy: 0.9780\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.0653 - accuracy: 0.9795 - val_loss: 0.0501 - val_accuracy: 0.9835\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 27s 28ms/step - loss: 0.0469 - accuracy: 0.9850 - val_loss: 0.0444 - val_accuracy: 0.9850\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 27s 28ms/step - loss: 0.0376 - accuracy: 0.9882 - val_loss: 0.0372 - val_accuracy: 0.9866\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.0324 - accuracy: 0.9897 - val_loss: 0.0366 - val_accuracy: 0.9874\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.0360 - val_accuracy: 0.9880\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.0311 - val_accuracy: 0.9902\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 27s 28ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0429 - val_accuracy: 0.9882\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0349 - val_accuracy: 0.9899\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.0386 - val_accuracy: 0.9885\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 24, 24, 6)         156       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 12, 12, 6)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 16)          2416      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 120)               30840     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44426 (173.54 KB)\n",
            "Trainable params: 44426 (173.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "conv2d_2 156\n",
            "max_pooling2d_2 0\n",
            "conv2d_3 2416\n",
            "max_pooling2d_3 0\n",
            "flatten_1 0\n",
            "dense_3 30840\n",
            "dense_4 10164\n",
            "dense_5 850\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "(MNIST):\n",
            "Confusion Matrix :\n",
            "[[ 972    0    1    0    0    1    2    2    2    0]\n",
            " [   0 1127    3    1    0    1    0    1    2    0]\n",
            " [   1    0 1025    0    0    0    0    5    1    0]\n",
            " [   0    0    5  996    0    4    0    0    5    0]\n",
            " [   0    1    1    0  974    0    0    1    1    4]\n",
            " [   1    0    0    2    0  887    1    0    1    0]\n",
            " [   4    3    1    0    3    2  945    0    0    0]\n",
            " [   0    1    9    0    0    0    0 1016    1    1]\n",
            " [   0    0    4    1    0    1    0    1  967    0]\n",
            " [   0    0    0    0   11    6    0    5   11  976]]\n",
            "Precision: 0.9885855733592138\n",
            "Recall: 0.9885\n",
            "F1 Score: 0.9884999794799305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fashion MNIST\n",
        "model_fashion = models.Sequential([\n",
        "    layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(120, activation='relu'),\n",
        "    layers.Dense(84, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_fashion.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_fashion.fit(X_train_fashion, y_train_fashion, epochs=10, batch_size=64, validation_data=(X_test_fashion, y_test_fashion))\n",
        "\n",
        "model_fashion.summary()\n",
        "for layer in model_fashion.layers:\n",
        "    print(layer.name, layer.count_params())\n",
        "\n",
        "y_pred_fashion = model_fashion.predict(X_test_fashion)\n",
        "y_pred_classes_fashion = np.argmax(y_pred_fashion, axis=1)\n",
        "y_true_fashion = np.argmax(y_test_fashion, axis=1)\n",
        "\n",
        "confusion_fashion = confusion_matrix(y_true_fashion, y_pred_classes_fashion)\n",
        "precision_fashion = precision_score(y_true_fashion, y_pred_classes_fashion, average='weighted')\n",
        "recall_fashion = recall_score(y_true_fashion, y_pred_classes_fashion, average='weighted')\n",
        "f1_fashion = f1_score(y_true_fashion, y_pred_classes_fashion, average='weighted')\n",
        "\n",
        "print(\"(Fashion MNIST):\")\n",
        "print(\"Confusion Matrix :\")\n",
        "print(confusion_fashion)\n",
        "print(f\"Precision : {precision_fashion}\")\n",
        "print(f\"Recall : {recall_fashion}\")\n",
        "print(f\"F1 Score : {f1_fashion}\")\n"
      ],
      "metadata": {
        "id": "RRA4-bbn-AgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41bf1bf3-e00d-431f-c80e-0d86a49dae75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 30s 31ms/step - loss: 0.6112 - accuracy: 0.7753 - val_loss: 0.4488 - val_accuracy: 0.8411\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.3904 - accuracy: 0.8593 - val_loss: 0.3755 - val_accuracy: 0.8670\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.3370 - accuracy: 0.8781 - val_loss: 0.3439 - val_accuracy: 0.8759\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.3073 - accuracy: 0.8871 - val_loss: 0.3303 - val_accuracy: 0.8830\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 37s 39ms/step - loss: 0.2861 - accuracy: 0.8952 - val_loss: 0.3330 - val_accuracy: 0.8806\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.2697 - accuracy: 0.9002 - val_loss: 0.3050 - val_accuracy: 0.8896\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.2552 - accuracy: 0.9050 - val_loss: 0.3153 - val_accuracy: 0.8857\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 28s 29ms/step - loss: 0.2439 - accuracy: 0.9090 - val_loss: 0.2949 - val_accuracy: 0.8952\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.2302 - accuracy: 0.9144 - val_loss: 0.2988 - val_accuracy: 0.8927\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.2218 - accuracy: 0.9179 - val_loss: 0.3028 - val_accuracy: 0.8948\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 24, 24, 6)         156       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 12, 12, 6)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 16)          2416      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 120)               30840     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44426 (173.54 KB)\n",
            "Trainable params: 44426 (173.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "conv2d_4 156\n",
            "max_pooling2d_4 0\n",
            "conv2d_5 2416\n",
            "max_pooling2d_5 0\n",
            "flatten_2 0\n",
            "dense_6 30840\n",
            "dense_7 10164\n",
            "dense_8 850\n",
            "313/313 [==============================] - 2s 5ms/step\n",
            "(Fashion MNIST):\n",
            "Confusion Matrix :\n",
            "[[854   1  13  36   9   1  79   0   7   0]\n",
            " [  3 974   0  17   4   0   1   0   1   0]\n",
            " [ 17   1 815   8  84   0  74   0   1   0]\n",
            " [ 10   5   5 906  50   0  23   0   1   0]\n",
            " [  1   1  41  18 881   0  57   0   1   0]\n",
            " [  0   0   0   0   0 987   0   8   0   5]\n",
            " [146   0  49  32  76   0 689   0   8   0]\n",
            " [  0   0   0   0   0  56   0 931   1  12]\n",
            " [  4   2   6   4   5   4   4   3 968   0]\n",
            " [  1   0   0   0   0  14   0  42   0 943]]\n",
            "Precision : 0.8954047149508754\n",
            "Recall : 0.8948\n",
            "F1 Score : 0.8944825146594026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10\n",
        "model_cifar = models.Sequential([\n",
        "    layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Conv2D(16, kernel_size=(5, 5), activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(120, activation='relu'),\n",
        "    layers.Dense(84, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cifar.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cifar.fit(X_train_cifar, y_train_cifar, epochs=10, batch_size=64, validation_data=(X_test_cifar, y_test_cifar))\n",
        "\n",
        "model_cifar.summary()\n",
        "for layer in model_cifar.layers:\n",
        "    print(layer.name, layer.count_params())\n",
        "\n",
        "y_pred_cifar = model_cifar.predict(X_test_cifar)\n",
        "y_pred_classes_cifar = np.argmax(y_pred_cifar, axis=1)\n",
        "y_true_cifar = np.argmax(y_test_cifar, axis=1)\n",
        "\n",
        "confusion_cifar = confusion_matrix(y_true_cifar, y_pred_classes_cifar)\n",
        "precision_cifar = precision_score(y_true_cifar, y_pred_classes_cifar, average='weighted')\n",
        "recall_cifar = recall_score(y_true_cifar, y_pred_classes_cifar, average='weighted')\n",
        "f1_cifar = f1_score(y_true_cifar, y_pred_classes_cifar, average='weighted')\n",
        "\n",
        "print(\"(CIFAR-10):\")\n",
        "print(\"Confusion Matrix :\")\n",
        "print(confusion_cifar)\n",
        "print(f\"Precision : {precision_cifar}\")\n",
        "print(f\"Recall : {recall_cifar}\")\n",
        "print(f\"F1 Score : {f1_cifar}\")"
      ],
      "metadata": {
        "id": "ejoQgKUX6Tcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c6e92f-2719-4f67-901a-1eab0d871255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 40s 50ms/step - loss: 1.6976 - accuracy: 0.3821 - val_loss: 1.4877 - val_accuracy: 0.4564\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 1.4225 - accuracy: 0.4840 - val_loss: 1.3509 - val_accuracy: 0.5152\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 1.3123 - accuracy: 0.5274 - val_loss: 1.2775 - val_accuracy: 0.5442\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.2373 - accuracy: 0.5568 - val_loss: 1.2629 - val_accuracy: 0.5478\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 36s 47ms/step - loss: 1.1758 - accuracy: 0.5795 - val_loss: 1.2027 - val_accuracy: 0.5723\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 36s 47ms/step - loss: 1.1208 - accuracy: 0.6004 - val_loss: 1.1782 - val_accuracy: 0.5812\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.0676 - accuracy: 0.6222 - val_loss: 1.1400 - val_accuracy: 0.6013\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.0297 - accuracy: 0.6333 - val_loss: 1.1446 - val_accuracy: 0.6016\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.9959 - accuracy: 0.6465 - val_loss: 1.1838 - val_accuracy: 0.5956\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 36s 47ms/step - loss: 0.9598 - accuracy: 0.6587 - val_loss: 1.1341 - val_accuracy: 0.6081\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 14, 14, 6)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 5, 5, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 120)               48120     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62006 (242.21 KB)\n",
            "Trainable params: 62006 (242.21 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "conv2d_6 456\n",
            "max_pooling2d_6 0\n",
            "conv2d_7 2416\n",
            "max_pooling2d_7 0\n",
            "flatten_3 0\n",
            "dense_9 48120\n",
            "dense_10 10164\n",
            "dense_11 850\n",
            "313/313 [==============================] - 3s 9ms/step\n",
            "(CIFAR-10):\n",
            "Confusion Matrix :\n",
            "[[656  22  71  15  41  10  16  40  74  55]\n",
            " [ 35 655  19   9   9   5  19  26  29 194]\n",
            " [ 45   7 517  56 136  62  66  80  16  15]\n",
            " [ 12  12  91 380 123 154  96  89  16  27]\n",
            " [ 19   1  84  26 605  28  51 166   9  11]\n",
            " [  8   7  91 175  86 451  34 129   7  12]\n",
            " [  5   3  72  50 113  18 676  43   6  14]\n",
            " [  7   2  33  29  71  42  12 767   5  32]\n",
            " [125  54  18  15  18  10  15  14 686  45]\n",
            " [ 42 107  12  15  12  10  23  51  40 688]]\n",
            "Precision : 0.6134671656614685\n",
            "Recall : 0.6081\n",
            "F1 Score : 0.6061998522333206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Comment on Results***"
      ],
      "metadata": {
        "id": "hNU-dDJYAz0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LeNet-5 architecture was primarily designed for the MNIST dataset, which contains grayscale images of handwritten digits so as the Fashion MNIST its grayscale images of clothes.the LeNet-5 is relatively simple CNN  that might not be well-suited for the more complex CIFAR-10 dataset, which contains color images of various objects and scenes.\n",
        "###***Complexity of Data:***###\n",
        "-->MNIST and fashion MNIST images are simple and consist of single-channel.The images are relatively low resolution (28x28 pixels), making it easier for LeNet-5 to extract relevant features and classify them accurately.\n",
        "\n",
        "-->CIFAR-10 images are more complex. They are color images with three channels (RGB) and contain various objects in cluttered backgrounds. The images are higher resolution (32x32 pixels), which makes feature extraction and classification more challenging.\n",
        "\n",
        "###***Model Complexity:***###\n",
        "\n",
        "LeNet-5 is a relatively simple CNN architecture with fewer layers and parameters. It may lack the capacity to capture the intricate features present in CIFAR-10 images.\n",
        "\n",
        "###***Color Information:***###\n",
        "\n",
        "LeNet-5 was not designed to handle color information, as it operates on grayscale images (MNIST ,fashion MNIST). CIFAR-10, being a color dataset, contains valuable color information that is not fully utilized by LeNet-5.\n"
      ],
      "metadata": {
        "id": "qoBoVAuPLxBq"
      }
    }
  ]
}